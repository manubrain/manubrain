{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "71a68ee2",
   "metadata": {},
   "source": [
    "This notebook will read data from the InfluxDB and use it to train the TCN model. Then it will use this model to continuously output an anomaly score back to the InfluxDB which can be output there via bucket-->anomalies-->tcn-->anomaly_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0c52e0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "###Enter the information from the InfluxDB here.\n",
    "###In particular, be sure not to remove the outer quotation marks for the bucket and the measurement variables.\n",
    "###Fields need to be given as lists\n",
    "\n",
    "organisation = \"manubrain\"\n",
    "bucket = 'sinus'\n",
    "msm = 'anomalie_detection'\n",
    "fields = ['field_0','field_1','field_2','field_3','field_4','field_5','field_6','field_7','field_8','field_9']\n",
    "\n",
    "###Give the time_window for how far we should go into the past to construct the training data\n",
    "import datetime\n",
    "endtime = datetime.datetime.now()\n",
    "# endtime = datetime.datetime.strptime(\"15-12-22 11:00:00\", '%d-%m-%y %H:%M:%S')\n",
    "# Getting the start time based on the time delta\n",
    "time_change = datetime.timedelta(hours=-1)\n",
    "starttime = endtime + time_change\n",
    "\n",
    "###Give the desired number of training epochs of the method\n",
    "epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b16c299",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install torch\n",
    "!pip install -e /home/jovyan/detect\n",
    "!pip install influxdb-client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46d672df-4e81-483b-b01b-66b4a59e8fc3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from mb_detect.models.classic import sklearn_dect\n",
    "from mb_detect.models.deep.tcn_model import TCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b3228f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2e66618",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONFIGURATION\n",
    "import influxdb_client, os, time\n",
    "from influxdb_client import InfluxDBClient, Point, WritePrecision\n",
    "from influxdb_client.client.write_api import SYNCHRONOUS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "236b565d",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"http://influxdb:8086\"\n",
    "token = os.environ.get(\"INFLUXDB_TOKEN\")\n",
    "client = influxdb_client.InfluxDBClient(url=url, token=token, org=organisation)\n",
    "query_api = client.query_api()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a23d3d2",
   "metadata": {},
   "source": [
    "The fields need to be brought in the correct form for the query api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cd6ba1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "field_query = ''\n",
    "\n",
    "if len(fields) == 1:\n",
    "    field_query = 'r[\"_field\"] == ' + str(fields[0])\n",
    "    \n",
    "else:\n",
    "\n",
    "    for i in range(len(fields)-1):\n",
    "        field_query = field_query + 'r[\"_field\"] == \"' + fields[i] + '\"' + ' or '\n",
    "        \n",
    "    field_query = field_query + 'r[\"_field\"] == \"' + fields[-1] + '\"'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e9d1cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query script for loading the data from the influxDB\n",
    "def data_loader(bucket,msm,field_query,starttime, endtime):\n",
    "    st = starttime.strftime(\"%Y-%m-%dT%H:%M:%SZ\")\n",
    "    et = endtime.strftime(\"%Y-%m-%dT%H:%M:%SZ\")\n",
    "    query = 'from(bucket:\"{}\")\\\n",
    "    |> range(start: {}, stop: {})\\\n",
    "    |> filter(fn:(r) => r[\"_measurement\"] == \"{}\")\\\n",
    "    |> filter(fn:(r) => {})\\\n",
    "    |> pivot(rowKey:[\"_time\"], columnKey: [\"_field\"], valueColumn: \"_value\")'.format(bucket,st,et,msm,field_query)\n",
    "\n",
    "    data = query_api.query_data_frame(org=\"manubrain\", query=query)\n",
    "    \n",
    "    ###We need to rename to columns to the name 'value_nr' in order to be handable for the method\n",
    "    rename = {}\n",
    "    [rename.update({c:c.replace(\"field\", \"value\")}) for c in data.columns if c.startswith(\"field\")]\n",
    "    data.rename(columns=rename, inplace=True)\n",
    "    \n",
    "    return(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a7b5abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = data_loader(bucket,msm,field_query,starttime, endtime)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cb150c6",
   "metadata": {},
   "source": [
    "Train the TCN model on the chosen train data with the chosen number of epochs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b22428da",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_data[[c for c in train_data.columns if c.startswith(\"value\")]]\n",
    "model = TCN(X.shape[1])\n",
    "model.fit(X,epochs=epochs) #turn up epochs for better learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "827fd470",
   "metadata": {},
   "source": [
    "The model is used to make predictions on the next data point based on the last 5 data points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c22daeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_predictions_tcn(model):\n",
    "    _endtime = datetime.datetime.now()\n",
    "    _time_change = datetime.timedelta(seconds=-10)\n",
    "    _starttime = _endtime + _time_change\n",
    "    test_data = data_loader(bucket, msm, field_query, _starttime, _endtime)\n",
    "    test_data = test_data[[c for c in train_data.columns if c.startswith(\"value\")]]\n",
    "    tx = torch.Tensor(test_data.to_numpy()).T\n",
    "    history = tx[...,-6:-1]\n",
    "    predict_target = tx[...,-1].numpy()\n",
    "    predict_model = model.forward(history).detach().numpy().flatten()\n",
    "    predict_error = np.linalg.norm(predict_target-predict_model)\n",
    "    return [predict_error, _endtime, predict_target,predict_model]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "412c0402",
   "metadata": {},
   "source": [
    "Write data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e78eac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_api = client.write_api(write_options=SYNCHRONOUS)\n",
    "while True:\n",
    "    predictions = make_predictions_tcn(model)\n",
    "    predict_error = predictions[0]\n",
    "    predict_ts = predictions[1]\n",
    "\n",
    "    point = (\n",
    "      Point(\"anomalies\")\n",
    "      .tag(\"scores\", 'anomaly_score')\n",
    "      .field(\"tcn\", predict_error)\n",
    "      )\n",
    "    point.time(predict_ts)\n",
    "    write_api.write(bucket=bucket.replace('\"',\"\"), org=organisation, record=point)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}