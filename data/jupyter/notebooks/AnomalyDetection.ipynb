{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "71a68ee2",
   "metadata": {},
   "source": [
    "This notebook will read data from the InfluxDB and use it to train the TCN model. Then it will use this model to continuously output an anomaly score back to the InfluxDB which can be output there via bucket-->anomalies-->tcn-->anomaly_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f0c52e0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "###Enter the information from the InfluxDB here.\n",
    "###In particular, be sure not to remove the outer quotation marks for the bucket and the measurement variables.\n",
    "###Fields need to be given as lists\n",
    "\n",
    "organisation = \"manubrain\"\n",
    "bucket = '\"sinus\"'\n",
    "msm = '\"anomalie_detection\"'\n",
    "fields = ['field_0','field_1','field_2','field_3','field_4','field_5','field_6','field_7','field_8','field_9']\n",
    "\n",
    "###Give the time_window for how far we should go into the past to construct the training data\n",
    "time_window = \"1h\"\n",
    "\n",
    "###Give the desired number of training epochs of the method\n",
    "epochs = 10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c41c2926",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?2004h\u001b]0;jovyan@jupyter: ~/work\u0007\u001b[01;32mjovyan@jupyter\u001b[00m:\u001b[01;34m~/work\u001b[00m$ "
     ]
    }
   ],
   "source": [
    "!su jovyan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6b16c299",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: The directory '/home/jovyan/.cache/pip' or its parent directory is not owned or is not writable by the current user. The cache has been disabled. Check the permissions and owner of that directory. If executing pip with sudo, you should use sudo's -H flag.\u001b[0m\u001b[33m\n",
      "\u001b[0mObtaining file:///home/jovyan/detect\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting more_itertools\n",
      "  Downloading more_itertools-9.0.0-py3-none-any.whl (52 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.8/52.8 kB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from mb-detect==0.1.0) (4.64.1)\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.10/site-packages (from mb-detect==0.1.0) (8.1.3)\n",
      "Collecting more_click\n",
      "  Downloading more_click-0.1.2-py3-none-any.whl (6.7 kB)\n",
      "Collecting torch\n",
      "  Downloading torch-1.13.0-cp310-cp310-manylinux1_x86_64.whl (890.1 MB)\n",
      "\u001b[2K     \u001b[91m━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.9/890.1 MB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:02:54\u001b[0m^C\n",
      "\u001b[2K     \u001b[91m━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.0/890.1 MB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:02:53\u001b[0m\n",
      "\u001b[?25h\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "#!pip3 install torch torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/cpu\n",
    "!pip install -e /home/jovyan/detect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ce26df36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ls: cannot open directory '/home/jovyan/detect': Permission denied\r\n"
     ]
    }
   ],
   "source": [
    "!ls /home/jovyan/detect\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "972ac099",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mb_detect.models.classic import sklearn_dect\n",
    "from mb_detect.models.deep.tcn_model import TCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6b3228f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c2e66618",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONFIGURATION\n",
    "import influxdb_client, os, time\n",
    "from influxdb_client import InfluxDBClient, Point, WritePrecision\n",
    "from influxdb_client.client.write_api import SYNCHRONOUS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "236b565d",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"http://influxdb:8086\"\n",
    "token = os.environ.get(\"INFLUXDB_TOKEN\")\n",
    "client = influxdb_client.InfluxDBClient(url=url, token=token, org=organisation)\n",
    "query_api = client.query_api()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a23d3d2",
   "metadata": {},
   "source": [
    "The fields need to be brought in the correct form for the query api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1cd6ba1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "field_query = ''\n",
    "\n",
    "if len(fields) == 1:\n",
    "    field_query = 'r[\"_field\"] == ' + str(fields[0])\n",
    "    \n",
    "else:\n",
    "\n",
    "    for i in range(len(fields)-1):\n",
    "        field_query = field_query + 'r[\"_field\"] == \"' + fields[i] + '\"' + ' or '\n",
    "        \n",
    "    field_query = field_query + 'r[\"_field\"] == \"' + fields[-1] + '\"'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8e9d1cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query script for loading the data from the influxDB\n",
    "\n",
    "def data_loader(bucket,msm,field_query,time_window=\"10s\"):\n",
    "\n",
    "    query = 'from(bucket:{})\\\n",
    "    |> range(start: -{})\\\n",
    "    |> filter(fn:(r) => r._measurement == {})\\\n",
    "    |> filter(fn:(r) => {})\\\n",
    "    |> pivot(rowKey:[\"_time\"], columnKey: [\"_field\"], valueColumn: \"_value\")\\\n",
    "    '.format(bucket,time_window,msm,field_query)\n",
    "\n",
    "    data = query_api.query_data_frame(org=\"manubrain\", query=query)\n",
    "    \n",
    "    ###We need to rename to columns to the name 'value_nr' in order to be handable for the method\n",
    "    rename = {}\n",
    "    [rename.update({c:c.replace(\"field\", \"value\")}) for c in data.columns if c.startswith(\"field\")]\n",
    "    data.rename(columns=rename, inplace=True)\n",
    "    \n",
    "    return(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8a7b5abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = data_loader(bucket,msm,field_query,time_window=time_window)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cb150c6",
   "metadata": {},
   "source": [
    "Train the TCN model on the chosen train data with the chosen number of epochs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b22428da",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_data[[c for c in train_data.columns if c.startswith(\"value\")]]\n",
    "model = TCN(X.shape[1])\n",
    "model.fit(X,epochs=epochs) #turn up epochs for better learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "827fd470",
   "metadata": {},
   "source": [
    "The model is used to make predictions on the next data point based on the last 5 data points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5c22daeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_predictions_tcn(model):\n",
    "    import numpy as np\n",
    "    test_data = data_loader(bucket,msm,field_query,time_window=\"10s\")\n",
    "    test_data = test_data[[c for c in train_data.columns if c.startswith(\"value\")]]\n",
    "    tx = torch.Tensor(test_data.to_numpy()).T\n",
    "    history = tx[...,-6:-1]\n",
    "    predict_target = tx[...,-1].numpy()\n",
    "    predict_model = model.forward(history).detach().numpy().flatten()\n",
    "    predict_error = np.linalg.norm(predict_target-predict_model)\n",
    "    return [predict_error,predict_target,predict_model]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "412c0402",
   "metadata": {},
   "source": [
    "Write data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8e78eac9",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [12], line 12\u001b[0m\n\u001b[1;32m      6\u001b[0m point \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m      7\u001b[0m   Point(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124manomalies\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      8\u001b[0m   \u001b[38;5;241m.\u001b[39mtag(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscores\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124manomaly_score\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      9\u001b[0m   \u001b[38;5;241m.\u001b[39mfield(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtcn\u001b[39m\u001b[38;5;124m\"\u001b[39m, predict_error)\n\u001b[1;32m     10\u001b[0m   )\n\u001b[1;32m     11\u001b[0m write_api\u001b[38;5;241m.\u001b[39mwrite(bucket\u001b[38;5;241m=\u001b[39mbucket\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m), org\u001b[38;5;241m=\u001b[39morganisation, record\u001b[38;5;241m=\u001b[39mpoint)\n\u001b[0;32m---> 12\u001b[0m \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "write_api = client.write_api(write_options=SYNCHRONOUS)\n",
    "while True:\n",
    "    predictions = make_predictions_tcn(model)\n",
    "    predict_error = predictions[0]\n",
    "\n",
    "    point = (\n",
    "      Point(\"anomalies\")\n",
    "      .tag(\"scores\", 'anomaly_score')\n",
    "      .field(\"tcn\", predict_error)\n",
    "      )\n",
    "    write_api.write(bucket=bucket.replace('\"',\"\"), org=organisation, record=point)\n",
    "    time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e8fc25c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3a4e8de",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
