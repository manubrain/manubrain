{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook showcases a workflow to benchmark an anomaly detection model against a dataset of timeseries with anomaly labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mb_detect.dataloader import iter_reader, benchmarker\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize the reader of the dataset and the model. For a simple example we use a isolation forest from sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "nab_data_dir = \"./data/nab/data/\"\n",
    "nab_label_dir = \"./data/nab/labels/\"\n",
    "nab_reader = iter_reader.NabIter(data_dir=nab_data_dir, label_dir=nab_label_dir)\n",
    "from sklearn.ensemble import IsolationForest\n",
    "model = IsolationForest(n_estimators=100, warm_start=False, contamination=0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We iterate over the dataset with the reader. Everytime we apply the model against the timeseries and calculate the f1-score. We aggregate the f1-score over the different categories of timeseries in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def benchmark(model, reader):\n",
    "    group_scores = {}\n",
    "    for data, metadata in reader:\n",
    "        pred_outliers = benchmarker.test_unsupervised(data, model, window_size=50)\n",
    "        pred_outliers = pred_outliers == -1\n",
    "        true_outliers = data[\"is_anomaly\"]\n",
    "        true_outliers = true_outliers.to_numpy()\n",
    "        cm = benchmarker.compare_to_labels(true_outliers, pred_outliers)\n",
    "        f1_score = benchmarker.f_one_score(cm)\n",
    "        if (metadata[\"group\"] not in group_scores.keys()):\n",
    "            group_scores[metadata[\"group\"]] = [f1_score]\n",
    "        else:\n",
    "            group_scores[metadata[\"group\"]].append(f1_score)\n",
    "    for group_name, scores in group_scores.items():\n",
    "        print(group_name, np.round(np.mean(np.array(scores)), 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use this downloader if the Numenta dataset is not downloaded yet:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nab data folder exists already .\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<mb_detect.dataloader.nab_downloader.NabData at 0x7fbe7c778670>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from mb_detect.dataloader import nab_downloader\n",
    "\n",
    "nab_downloader.NabData(nab_path=\"./data/nab/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "realTweets 0.25\n",
      "artificialWithAnomaly 0.29\n",
      "realAWSCloudwatch 0.27\n",
      "realKnownCause 0.36\n",
      "realAdExchange 0.19\n",
      "artificialNoAnomaly 0.2\n",
      "realTraffic 0.34\n"
     ]
    }
   ],
   "source": [
    "benchmark(model, nab_reader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can conclude, that isolation forest does not sufficiently on these rather complex problems. However, with this API we can exchange components of the experiment with ease.\n",
    "\n",
    "Replace the Numenta dataset with the Yahoo dataset. For this dataset, we cannot provide a downloader, because it is behind an authentication wall. It can be downloaded after requesting access [here](https://webscope.sandbox.yahoo.com/catalog.php?datatype=s&did=70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "yahoo_data_dir = \"./data/yahoo/ydata-labeled-time-series-anomalies-v1_0/\"\n",
    "yahoo_reader = iter_reader.YahooIter(data_dir=yahoo_data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A2Benchmark 0.05\n",
      "A4Benchmark 0.28\n",
      "A3Benchmark 0.37\n",
      "A1Benchmark 0.31\n"
     ]
    }
   ],
   "source": [
    "benchmark(model, yahoo_reader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('manubrain': conda)",
   "language": "python",
   "name": "python38864bitmanubraincondad4c53a4353354d20a0a631ccae7dd72a"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
